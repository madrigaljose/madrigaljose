{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "deep_net_in_keras_tuner.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIFsW_yzVXWx"
      },
      "source": [
        "# Deep Neural Network in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txev85-3VXWy"
      },
      "source": [
        "In this notebook, we improve on our [intermediate neural net](https://github.com/the-deep-learners/deep-learning-illustrated/blob/master/notebooks/intermediate_net_in_keras.ipynb) by applying the theory we've covered since."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMEURlJoVXWz"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/the-deep-learners/deep-learning-illustrated/blob/master/notebooks/deep_net_in_keras.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPJkxBZZVXWz"
      },
      "source": [
        "#### Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiUtOxf1rMh3"
      },
      "source": [
        "#!pip install keras-tuner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyUk1tnzVXWz"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout # new!\n",
        "from tensorflow.keras.layers import BatchNormalization # new!\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "import kerastuner as kt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6RkKfbIVXW0"
      },
      "source": [
        "#### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfU5z2Z7VXW0"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "932GrKIIVXW1"
      },
      "source": [
        "#### Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqbJ3PMSVXW1"
      },
      "source": [
        "X_train = X_train.reshape(60000, 784).astype('float32')\n",
        "X_test = X_test.reshape(10000, 784).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he5sWj6oVXW1"
      },
      "source": [
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHEq4HjtVXW1"
      },
      "source": [
        "n_classes = 10\n",
        "y_train = to_categorical(y_train, n_classes)\n",
        "y_test = to_categorical(y_test, n_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu0jkGkBVXW2"
      },
      "source": [
        "#### Define Model Builder Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjUPujEaVXW2"
      },
      "source": [
        "def model_builder(hp):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(units=hp.Choice('l1_units', values=[32,64])\n",
        "                  ,activation='relu', input_shape=(784,)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dense(units=hp.Choice('l2_units', values=[32,64])\n",
        "                  ,activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dense(units=hp.Choice('l3_units', values=[32,64])\n",
        "                  ,activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(hp.Float('do_rate', min_value=0.1, max_value=0.3, sampling='linear')))\n",
        "\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]))\n",
        "                ,metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30lkOyDGVXW2"
      },
      "source": [
        "#### Create Tuners\n",
        "\n",
        "\n",
        "https://keras-team.github.io/keras-tuner/documentation/tuners/#tuners"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg-gxbz02cmV"
      },
      "source": [
        "# for reproducibility\n",
        "SEED = 1\n",
        "\n",
        "\n",
        "# max number of epochs that a model can be trained for using Hyperband tuner\n",
        "HYPERBAND_MAX_EPOCHS = 40\n",
        "\n",
        "# number of hyperparameter combinations (number of rounds) that will be tested by the tuner\n",
        "MAX_TRIALS = 10\n",
        "\n",
        "# number of models that should be built and fit for each trial for robustness purposes\n",
        "EXECUTION_PER_TRIAL = 2\n",
        "\n",
        "BAYESIAN_NUM_INITIAL_POINTS = 1\n",
        "\n",
        "# directory for each search\n",
        "RANDOM_DIR = \"random-search-{}\".format(int(time.time()))\n",
        "HYPERBAND_DIR = \"hyperband-search-{}\".format(int(time.time()))\n",
        "BAYESIAN_DIR = \"bayesian-search-{}\".format(int(time.time()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mcq59PIvVXW2"
      },
      "source": [
        "random_tuner = kt.RandomSearch(model_builder, objective='val_accuracy', seed=SEED, max_trials=MAX_TRIALS, executions_per_trial=EXECUTION_PER_TRIAL, directory=RANDOM_DIR, project_name='deep_net_tuner')\n",
        "hyper_tuner = kt.Hyperband(model_builder, objective='val_accuracy', max_epochs=HYPERBAND_MAX_EPOCHS, seed=SEED, executions_per_trial=EXECUTION_PER_TRIAL, directory=HYPERBAND_DIR, project_name='deep_net_tuner')\n",
        "bayesian_tuner = kt.BayesianOptimization(model_builder, objective='val_accuracy', num_initial_points=BAYESIAN_NUM_INITIAL_POINTS, seed=SEED, max_trials=MAX_TRIALS, executions_per_trial=EXECUTION_PER_TRIAL, directory=BAYESIAN_DIR, project_name='deep_net_tuner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaozIvioVXW3"
      },
      "source": [
        "#### Search for Best Parameters using RandomSearch tuner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7THTPjIkVXW3"
      },
      "source": [
        "random_tuner.search(X_train, y_train, batch_size=128, epochs=20, verbose=1, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnQqt5EhzlKw"
      },
      "source": [
        "best_random_hps=random_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The random search is complete\n",
        "The optimal number of units in the first layer is {best_random_hps.get('l1_units')}.\n",
        "optimal number of units in the second layer is {best_random_hps.get('l2_units')}.\n",
        "optimal number of units in the third layer is {best_random_hps.get('l3_units')}.\n",
        "optimal dropout rate is {best_random_hps.get('do_rate')}.\n",
        "optimal learning rate for the optimizer is {best_random_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj7vyCmqIGtS"
      },
      "source": [
        "###Hyperband Search\n",
        "__CAUTION__: This will run for quite a while"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx8zMcIuFups"
      },
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "hyper_tuner.search(X_train, y_train, batch_size=128, epochs=20, verbose=1, validation_split=0.2, callbacks=[stop_early])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zzhmz9xFFxii"
      },
      "source": [
        "best_hyper_hps=hyper_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperband search is complete\n",
        "The optimal number of units in the first layer is {best_hyper_hps.get('l1_units')}.\n",
        "optimal number of units in the second layer is {best_hyper_hps.get('l2_units')}.\n",
        "optimal number of units in the third layer is {best_hyper_hps.get('l3_units')}.\n",
        "optimal dropout rate is {best_hyper_hps.get('do_rate')}.\n",
        "optimal learning rate for the optimizer is {best_hyper_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERIUdr5yIjE6"
      },
      "source": [
        "### Bayesian Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N-PNBgiGJbV"
      },
      "source": [
        "bayesian_tuner.search(X_train, y_train, batch_size=128, epochs=20, verbose=1, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQPMozQxGV6V"
      },
      "source": [
        "best_bayesian_hps=bayesian_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The bayesian optimization search is complete\n",
        "The optimal number of units in the first layer is {best_bayesian_hps.get('l1_units')}.\n",
        "optimal number of units in the second layer is {best_bayesian_hps.get('l2_units')}.\n",
        "optimal number of units in the third layer is {best_bayesian_hps.get('l3_units')}.\n",
        "optimal dropout rate is {best_bayesian_hps.get('do_rate')}.\n",
        "optimal learning rate for the optimizer is {best_bayesian_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z7VsopA5INW"
      },
      "source": [
        "tuner = random_tuner\n",
        "best_hps = best_random_hps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joaO5SOZ5BiD"
      },
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzUEKRHZ5in-"
      },
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(X_train, y_train, epochs=best_epoch, validation_split=0.2, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X62wmU6w4jEp"
      },
      "source": [
        "generalization_result = hypermodel.evaluate(X_test, y_test)\n",
        "print(\"[test loss, test accuracy]:\", generalization_result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}